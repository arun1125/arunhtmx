{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "My idea of what a model is has changed a lot over time \n",
    "\n",
    "I can't even begin to describe my ignorant start, it was insane. Nothing made sense\n",
    "\n",
    "the true understanding of what a model could be \n",
    "that understanding was true only relative to a mindset\n",
    "The bad ways of building a model \n",
    "evolution of the process - ground up\n",
    "\n",
    "I don't think I quite understood what a model really was when I was at university, but looking back I had NO understanding of anything back then\n",
    "The maths makes a lot more sense now but to me I was so lost at the age of 19-21 studying this crap \n",
    "\n",
    "A model can be anything\n",
    "\n",
    "The mean is a model \n",
    "\n",
    "The median is a model \n",
    "\n",
    "Just predicting 1 is a model \n",
    "\n",
    "anything can be a model \n",
    "\n",
    "Any rule for a prediction is a model \n",
    "\n",
    "its so simple now but back then I couldn't get my head around it \n",
    "\n",
    "While in my ignorant state I found Machine Learning through a course my friends were taking and I just felt socially pressured to join in \n",
    "it was a interesting course, I got a 50. Lets not talk about that! but it talk me enough to bullshit myway through a phone interview and into a data science internship which was enough at the time lol.\n",
    "\n",
    "fast forward a few years and I was building models at a Bank in Toronto. The standard way was to just throw a tree based model, choose the best features, then build a model on that. But this is essentially what a few AutoML tools are doing. You're just finding some soup of features, parameters and data that produces the best error score. \n",
    "\n",
    "looking back I understand why, it's just the simplest thing to do \n",
    "\n",
    "But the way model building should be done is through iteration and the ground up \n",
    "\n",
    "This is nice if you have a handful of features, of course if you're using 100's of features at a time then im unsure I guess I would still take a similar approach but with clusters of features and doing higher level analysis \n",
    "\n",
    "regardless, \n",
    "\n",
    "look at your data \n",
    "check what the columns are\n",
    "what is the problem you are trying to answer \n",
    "any columns match that (purely based on name)?\n",
    "oh great you found a few, even some basic features and a target \n",
    "Split the data \n",
    "create a model \n",
    "keep it crude \n",
    "okay how does it fit on the data\n",
    "look at the errors\n",
    "are they correlated with any of the features you did not use? \n",
    "the model you used, what were the assumptions behind it? \n",
    "do you need to make a transformation? \n",
    "Do you want to try add another feature? \n",
    "Do you want to just take all the features, create a massive basis expansion,\n",
    "then lasso to the data? \n",
    "\n",
    "\n",
    "Navigating this tree, using your gut instinct, building a model\n",
    "\n",
    "This takes time! and care and patience - which I have but I can greatly misuse because I leave model buidling till the end \n",
    "\n",
    "These people that tell you I spend most of my time making features and little time model building \n",
    "\n",
    "I thought that statement was valid but it is not \n",
    "\n",
    "the entire process is one whole unit, and you build the model from the ground up\n",
    "\n",
    "build model, look at errors, take data and analyse against the errors \n",
    "rinse repeat \n",
    "\n",
    "until you have your features generated which you will need to collect up your code and package it nicely into an efficient ETL \n",
    "Then create the model \n",
    "Then run it on the data\n",
    "Collect test set errors for reporting \n",
    "Deploy into A/B env \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
