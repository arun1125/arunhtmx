{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20a35ac",
   "metadata": {},
   "source": [
    "# Migrating Local Mongo DB to AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ad20c",
   "metadata": {},
   "source": [
    "This is actually probably a part 4 in a longer series around how I went from inception to deployment of my in game win probability app for NBA games, the problem is I spent an entire weekend learning about how to deploy things to AWS and thought I had to write about it to others in a similar predicament and before I forgot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a79a7",
   "metadata": {},
   "source": [
    "### MongoDB to AWS\n",
    "\n",
    "\n",
    "AWS has two options for noSQL db's, dynamoDB and DocumentDB\n",
    "Currently I am exploring how to set up dynamoDB but on my way to this point I figured out how to set up DocumentDB and it was kind of long to be honest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71a984",
   "metadata": {},
   "source": [
    "### Difference between DocumentDB and DynamoDB\n",
    "\n",
    "DynamoDB is Serverless where as DocumentDB is not.\n",
    "In terms of dollar value (which is what we all care about at the end of the day). DyanmoDB is pay per use/as you use resources and DocumentDB is pay hourly.\n",
    "\n",
    "Also querying the databases are different - docDB can be intereacted with the mongodb driver where as dynamoDB has it's own api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd201a11",
   "metadata": {},
   "source": [
    "## Setting up Document DB\n",
    "\n",
    "#### Steps\n",
    "\n",
    "- 1) okay look yeah you're going to need an AWS account, this shit ain't free (well the free stuff is free but documentDB doesn't have a free tier) - (writing this after my first day of docDB charges and damn re-reading this hurt my soul) \n",
    "- 2) Access, AWS handles access through the IAM - Identity and Access Manager. You will need to create a new user and add the appropriate policies to it. AmazonDocDBFullAccess.\n",
    "- 3) Create a VPC for your documentDB \n",
    "- 4) Create an EC2 instance \n",
    "    - why? okay so heres the annoying part about using documentDB it can only interact with other aws services within the same vpc. \n",
    "    - what does that mean for you? (or me) - well it means uploading the data from my local mongoDB is going to be a pain and we're going to use the EC2 instance as a sort of intermediary between us and documentDB\n",
    "    \n",
    "- 5) Create a security group so that your EC2 instance can actually connect to your documentDB\n",
    "- 6) Create your DocumentDB cluster\n",
    "- 7) Connect your EC2 instance to your Document DB cluster\n",
    "- 8) Install the Mongo Shell on your EC2 instance\n",
    "- 9) Manage TLS \n",
    "- 10) Test Connection with mongo shell \n",
    "- 11) Install Jupyter notebooks and pymongo on EC2 instance \n",
    "- 12) SCP your local CSV file to your EC2 instance\n",
    "- 13) insert your data into documentDB w chunksize probably since you'll be choosing a cheap instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f429bfa",
   "metadata": {},
   "source": [
    "For Steps 1 - 10 you can follow this document [https://docs.aws.amazon.com/documentdb/latest/developerguide/connect-ec2.html](https://docs.aws.amazon.com/documentdb/latest/developerguide/connect-ec2.html)\n",
    "\n",
    "It will get you up and running with the services "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b4791",
   "metadata": {},
   "source": [
    "Step 11\n",
    "\n",
    "- You can follow parts of this tutorial - https://chrisalbon.com/code/aws/basics/run_project_jupyter_on_amazon_ec2/\n",
    "- _right click_ and *COPY LINK ADDRESS* https://www.anaconda.com/products/individual\n",
    "- You won't need to set up a whole new virtual env as the reason for this ec2 instance is just to communicate with your docDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611c80e",
   "metadata": {},
   "source": [
    "Step 12\n",
    "\n",
    "Now that you have your docDB cluster set up, your ec2 instance set up and theyre in the same vpc we can now start sending our data over.\n",
    "\n",
    "- SCP/SFTP: You will need to ssh into your ec2 instance using the special .epm/.cer key that you downloaded following steps 1-10.\n",
    "\n",
    "- Download save your mongoDB database as a csv\n",
    "    - can be done through pd.DataFrame.from_records(db.collection.find()).to_csv('{name}.csv', index=False)\n",
    "\n",
    "- 'Put' your csv into your ec2 instance. The three datasets I was putting were ~7k rows, ~3million rows, ~3million rows. I also used the free tier instance but if its just for the file transfer and you don't want to do anything with chunksize i'd say just provision a larger instance for the file transfer then shut it down\n",
    "\n",
    "- Write your data to docDB, [how to programatically connect to docDB](https://docs.aws.amazon.com/documentdb/latest/developerguide/connect_programmatically.html)\n",
    "    - if you provisioned the smallest instance then in your script to be memory efficient you will need to create an iterator for your dataset that reads and writes chunks at a time.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b589be6a",
   "metadata": {},
   "source": [
    "## Why I'm trying DynamoDB?\n",
    "\n",
    "Using docDB as our primary database for our entire NBA ecosystem will slightly complicate any apps I deploy to EB regarding VPCs/Security Groups etc. Currently I haven't figured out how to connect to docDB from my docker container but as I was figuring this out guess what happened?  \n",
    "\n",
    "They charged me 9$ (Freedom not Maple) for hosting my DB for a day ... infact it was overnight! once I saw this bill I said screw it i'm moving to dynamoDB for serverless hosting as they will charge depending on traffic! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed014cf",
   "metadata": {},
   "source": [
    "## Setting up DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1cb22",
   "metadata": {},
   "source": [
    "Setting up DynamoDB is A LOT easier than before. In fact it can be done through your local machine. \n",
    "\n",
    "#### Prerequisites \n",
    "\n",
    "- Have the Python SDK for AWS installed on your pc (it's called boto3, I don't know why though)\n",
    "- Obviously have an AWS account lol \n",
    "\n",
    "_note_: the api is a little weird if you haven't seen stuff like this before, and i'm not too entirely comfortable with it either however, working through examples and being able to perform CRUD and some batch operations should get you up and running enough to go out and debug examples on your own\n",
    "\n",
    "For our example below we will be uploading the same .csv files as in our docDB walk through. Specifically: game_log and historical_pbp_modelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed20696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your imports\n",
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826bf760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you make your connection to dynamoDB through the boto3 resources method\n",
    "dynamoDB = boto3.resource('dynamodb', region_name = 'us-east-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you might have to include your accessID and secret ID from your IAM role if it isnt automatically detected\n",
    "#in that case you just set up a session \n",
    "access_id = 'wouldnt you like to know'\n",
    "secret_id = 'I aint telling you'\n",
    "\n",
    "session = boto3.Session(access_id, secret_id)\n",
    "dynamoDB = session.resource('dynamoDB', region_name = 'us-east-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6ade9",
   "metadata": {},
   "source": [
    "Now that we have the dynamoDB object to interact with we can start to create tables but before we do that you need to know how you are going to use the table. Knowing this will allow us to design the appropriate index structure to for efficent lookups.\n",
    "\n",
    "An Example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861bf01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON_ID</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>WL</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>VIDEO_AVAILABLE</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>home_team_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612744</td>\n",
       "      <td>GSW</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>21500003</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>GSW vs. NOP</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>GSW</td>\n",
       "      <td>NOP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>21500002</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>CHI vs. CLE</td>\n",
       "      <td>W</td>\n",
       "      <td>240</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>21500001</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>ATL vs. DET</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>LAL</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>21500017</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>LAL vs. MIN</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>111</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>LAL</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22015</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>21500014</td>\n",
       "      <td>2015-10-28</td>\n",
       "      <td>PHX vs. DAL</td>\n",
       "      <td>L</td>\n",
       "      <td>240</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>-16</td>\n",
       "      <td>1</td>\n",
       "      <td>PHX</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON_ID     TEAM_ID TEAM_ABBREVIATION              TEAM_NAME   GAME_ID  \\\n",
       "0      22015  1610612744               GSW  Golden State Warriors  21500003   \n",
       "1      22015  1610612741               CHI          Chicago Bulls  21500002   \n",
       "2      22015  1610612737               ATL          Atlanta Hawks  21500001   \n",
       "3      22015  1610612747               LAL     Los Angeles Lakers  21500017   \n",
       "4      22015  1610612756               PHX           Phoenix Suns  21500014   \n",
       "\n",
       "    GAME_DATE      MATCHUP WL  MIN  FGM  ...  STL  BLK  TOV  PF  PTS  \\\n",
       "0  2015-10-27  GSW vs. NOP  W  240   41  ...    8    7   20  29  111   \n",
       "1  2015-10-27  CHI vs. CLE  W  240   37  ...    6   10   13  22   97   \n",
       "2  2015-10-27  ATL vs. DET  L  240   37  ...    9    4   15  25   94   \n",
       "3  2015-10-28  LAL vs. MIN  L  240   35  ...    2    4   14  29  111   \n",
       "4  2015-10-28  PHX vs. DAL  L  240   34  ...    3    3   18  30   95   \n",
       "\n",
       "   PLUS_MINUS  VIDEO_AVAILABLE  Home  Away  home_team_win  \n",
       "0          16                1   GSW   NOP            1.0  \n",
       "1           2                1   CHI   CLE            1.0  \n",
       "2         -12                1   ATL   DET            0.0  \n",
       "3          -1                1   LAL   MIN            0.0  \n",
       "4         -16                1   PHX   DAL            0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_log = pd.read_csv('../NBA/Data/game_log.csv').drop('_id', axis = 1)\n",
    "game_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e843136",
   "metadata": {},
   "source": [
    "For our in game win probability use case we want the user:\n",
    "- 1) To be able to select a date\n",
    "- 2) Pick the games from this date they want to see the win probability for.\n",
    "\n",
    "To achieve this with a regular SQL db, amazon RDS, mongo/noSQL db, docDB is pretty simple but with dynamoDB it can get a little tricky. The tricky part is in the inital learning but after that it becomes a lot clearer.\n",
    "\n",
    "\n",
    "## DynamoDB key structure\n",
    "\n",
    "- Hash Key(aka Partition Key): \n",
    "    - This is a required key\n",
    "    - _Single_ Tables are defined as tables that ONLY have a Hash Key. \n",
    "        - A single table is something you generally want to avoid with dynamoDB because it limits you to one read at a time as it **only** enables the get_item method. I'm gyuessing this isn't what you want and that you'll probably want to query your data\n",
    "    - This is the main key and _must_ be unique\n",
    "\n",
    "\n",
    "unless you have a ...\n",
    "\n",
    "- Sort Key(aka Range key): \n",
    "    - This is an optional second key but can be used in conjunction with the Hash key to create a _Composite_ index where your Hash/Sort Key pair HAS to be unique. \n",
    "    - Having a composite key will allow us to perform more complex methods to retrieve data from our dynamoDB including Query and Scan operations.\n",
    "    \n",
    "For our use case we will create a composite key consisting of our GAME_DATE as our HASH key and GAME_ID as our SORT key. \n",
    "\n",
    "The Reason I have mentioned these BEFORE we create the table is because once created we can't change it. Annoying, but is it really a bug or feature lol.\n",
    "\n",
    "\n",
    "[Further Reading on this topic](https://dynobase.dev/dynamodb-keys/#:~:text=Is%20it%20possible%20to%20change,then%20remove%20the%20first%20table.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the table\n",
    "\n",
    "game_log_ddb = dynamodb.create_table(\n",
    "        TableName='game_log',\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'GAME_DATE',\n",
    "                'KeyType': 'HASH'  # Partition key\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'GAME_ID',\n",
    "                'KeyType': 'RANGE' # Sort key\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'GAME_DATE',\n",
    "                'AttributeType': 'S' #string\n",
    "            },\n",
    "            {\n",
    "                'AttributeName': 'GAME_ID',\n",
    "                'AttributeType': 'N' #number\n",
    "            },\n",
    "\n",
    "        ],\n",
    "    BillingMode= 'PAY_PER_REQUEST', \n",
    "    ) \n",
    "\n",
    "# A quick note on Billing Mode: PAY_PER_REQUEST provisions resources depending on traffic\n",
    "# and is useful if you don't know the frequency at which your db will get called\n",
    "# otherwise you can pre provision resources which will throttle read and write speeds\n",
    "# but for me since this app is a personal project I am going with PAY_PER_REQUEST for fast write speeds \n",
    "# during intial upload and I'll only be querying this db a handful of times a week. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76b269",
   "metadata": {},
   "source": [
    "# Time to write our local data. \n",
    "\n",
    "We cant just dump our csv in like mongoDB with the insert_many method instead we will have to create a _batch_writer_ object and load each row indvidually but if you selected BillingMode=PAY_PER_REQUEST then the data even if its in a for loop will be written in parallely. \n",
    "\n",
    "Additionally, floats arent compatible so you'll have to convert all your floats to Decimal (which I didn't even know was a type until getting to this step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_log_dict = game_log[~game_log['home_team_win'].isna()].to_dict(orient = 'records')\n",
    "#how we convert float to decimal\n",
    "game_log_json = [json.loads(json.dumps(item), parse_float=Decimal) for item in game_log_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import json\n",
    "\n",
    "#if a float column has a nan you will have problems - again this is annoying, alternatively you can convert your\n",
    "#data entirely to strings and then write it but Im going to get rid of the few rows that have nan in any float columns\n",
    "#I am working with\n",
    "\n",
    "\n",
    "with game_log_ddb.batch_writer() as batch:\n",
    "    for i in range(len(game_log_json)):\n",
    "        batch.put_item(Item = game_log_json[i])\n",
    "        \n",
    "        \n",
    "#should take under a minute for the ~7500 rows I have in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cc8a7",
   "metadata": {},
   "source": [
    "Doing this for the data that has the win probabilities ~3million rows took between 2-3 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd53b1",
   "metadata": {},
   "source": [
    "## How do you query the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0eec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "#Example query. GAME_DATE is our HASH KEY\n",
    "data = game_log_ddb.query(\n",
    "    KeyConditionExpression=Key('GAME_DATE').eq('2022-01-01')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e81b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to make a query with both GAME_DATE and GAME_ID then  \n",
    "\n",
    "data = game_log_ddb.query(\n",
    "    KeyConditionExpression=Key('GAME_DATE').eq(game_date) & Key('GAME_ID').eq(game_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15578320",
   "metadata": {},
   "source": [
    "## Global Secondary Indexes\n",
    "\n",
    "Okay, so you've moved your data from local to dynamoDB, you have everything wokring and have connected dynamoDB to your apis but as you move on with your project you realise that you need to use another column as a key to execute queries. What do you do? We can't reset the Partition key and Sort key that we originally set up + you need to use them anyways for your first use case. \n",
    "\n",
    "if only we could create another partition key and sort key? \n",
    "You can! and you can create/delete them even after the database has been created. They are called GSI's or Global Secondary Indexes and they allow you to perform queries like you would with your original partition and sort key!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960b1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = dynamoDB_client.update_table(\n",
    "    TableName=\"game_log\",\n",
    "    # Any attributes used in your new global secondary index must be declared in AttributeDefinitions\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            \"AttributeName\": \"GAME_ID\",\n",
    "            \"AttributeType\": \"N\"\n",
    "        },\n",
    "        {\n",
    "            \"AttributeName\": \"GAME_DATE\",\n",
    "            \"AttributeType\": \"S\"\n",
    "        }\n",
    "    ],\n",
    "    # This is where you add, update, or delete any global secondary indexes on your table.\n",
    "    GlobalSecondaryIndexUpdates=[\n",
    "        {\n",
    "            \"Create\": {\n",
    "                # You need to name your index and specifically refer to it when using it for queries.\n",
    "                \"IndexName\": \"GameIdIndex\",\n",
    "                # Like the table itself, you need to specify the key schema for an index.\n",
    "                # For a global secondary index, you can use a simple or composite key schema.\n",
    "                \"KeySchema\": [\n",
    "                    {\n",
    "                        \"AttributeName\": \"GAME_ID\",\n",
    "                        \"KeyType\": \"HASH\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"AttributeName\": \"GAME_DATE\",\n",
    "                        \"KeyType\": \"RANGE\"\n",
    "                    }\n",
    "                ],\n",
    "                # You can choose to copy only specific attributes from the original item into the index.\n",
    "                # You might want to copy only a few attributes to save space.\n",
    "                \"Projection\": {\n",
    "                    \"ProjectionType\": \"ALL\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "game_log_db.query(IndexName=\"GameIdIndex\",\n",
    "                  KeyConditionExpression=Key('GAME_ID').eq(22100540))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287e3f1",
   "metadata": {},
   "source": [
    "If you see here I created a global secondary index that reversed my original key structure just incase I wanted to search for games based purely of game_id!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908ba498",
   "metadata": {},
   "source": [
    "###### These articles are subject to revision because learning is a journey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006049a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
